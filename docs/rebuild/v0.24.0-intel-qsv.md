# v0.24.0 — Intel QSV Hardware Transcoding

> **Release:** v0.24.0
> **Phase:** 4.25b (Intel QSV Hardware Transcoding)
> **Goal:** Enable Intel Quick Sync Video hardware transcoding on all 3 nodes for Jellyfin mobile streaming
> **Prerequisite:** [v0.23.0-arr-stack.md](v0.23.0-arr-stack.md) completed, Jellyfin running with CPU transcoding

---

## Overview

Adds Intel QSV hardware transcoding to all 3 cluster nodes, allowing Jellyfin to transcode media in real-time with near-zero CPU impact. The stack uses Node Feature Discovery for GPU labeling, Intel Device Plugins for GPU resource scheduling, and Jellyfin's built-in `jellyfin-ffmpeg` with iHD VA-API driver.

```
Each K8s Node (i5-10400T / UHD 630 iGPU)
├── i915 driver + HuC firmware (enable_guc=2)
├── intel-media-va-driver-non-free (iHD)
└── /dev/dri/renderD128

Kubernetes
├── Node Feature Discovery (labels: intel.feature.node.kubernetes.io/gpu)
├── Intel Device Plugins Operator
│   └── Intel GPU Plugin DaemonSet
│       └── Advertises: gpu.intel.com/i915 (sharedDevNum=3)
└── Jellyfin Pod
    ├── resources.limits: gpu.intel.com/i915: "1"
    ├── supplementalGroups: [44, 993]  # video, render
    └── QSV: hevc_qsv -low_power 1 (HuC-enabled encode)
```

**Deployment order:** Node drivers first (Step 1), then Kubernetes components (Steps 2-3), then Jellyfin update (Step 4), then UI configuration (Step 5), then dashboards (Step 6).

---

## Step 1: Install Intel GPU Drivers (Ansible)

Run the Ansible playbook on all 3 nodes. This installs the VA-API driver, enables HuC firmware, and reboots nodes one at a time.

```bash
cd ansible
ansible-playbook -i inventory/homelab.yml playbooks/08-intel-gpu.yml
```

**What the playbook does (rolling, `serial: 1`):**
1. Verifies i915 module and `/dev/dri/renderD128` exist
2. Installs `intel-media-va-driver-non-free`, `vainfo`, `intel-gpu-tools`
3. Sets `fs.inotify.max_user_instances=512` (required for GPU plugin, Issue #2075)
4. Configures `enable_guc=2` in `/etc/modprobe.d/i915.conf` (HuC firmware)
5. Updates initramfs and reboots (only if config changed)
6. Verifies VA-API, HuC authentication, and kubelet on each node before proceeding

> **Note:** M80q BIOS POST takes 5-7 minutes. The playbook uses `reboot_timeout: 600`.

> **Note:** After each node reboot, you may need to clear stale OPNsense firewall states for the rebooted IP in Firewall > Diagnostics > States. Cross-VLAN SSH blocks until stale `CLOSED:SYN_SENT` entries expire.

### Verify on each node

```bash
# VA-API driver
vainfo --display drm --device /dev/dri/renderD128
# Expect: "Driver version: Intel iHD driver for Intel(R) Gen Graphics - 24.1.0"

# HuC firmware
sudo dmesg | grep -i huc
# Expect: "HuC authenticated"

# Group GIDs (needed for Jellyfin supplementalGroups)
getent group render video
# Expect: render:x:993, video:x:44
```

---

## Step 2: Deploy Node Feature Discovery

```bash
helm-homelab upgrade -i --create-namespace \
  -n node-feature-discovery node-feature-discovery \
  oci://registry.k8s.io/nfd/charts/node-feature-discovery \
  --version 0.18.3

# Apply Intel GPU feature rules
kubectl-homelab apply -f https://raw.githubusercontent.com/intel/intel-device-plugins-for-kubernetes/v0.34.1/deployments/nfd/overlays/node-feature-rules/node-feature-rules.yaml

# Verify GPU labels on all nodes
kubectl-homelab get nodes -o json | jq '.items[].metadata.labels | with_entries(select(.key | startswith("intel.feature")))'
# Expect: "intel.feature.node.kubernetes.io/gpu": "true" on all 3 nodes
```

---

## Step 3: Deploy Intel Device Plugins

```bash
# Add Intel Helm repo
helm-homelab repo add intel https://intel.github.io/helm-charts/
helm-homelab repo update

# Install operator (requires cert-manager)
helm-homelab upgrade -i --create-namespace \
  -n intel-device-plugins intel-device-plugins-operator \
  intel/intel-device-plugins-operator --version 0.34.1

# Install GPU plugin
helm-homelab upgrade -i \
  -n intel-device-plugins intel-device-plugins-gpu \
  -f helm/intel-gpu-plugin/values.yaml \
  intel/intel-device-plugins-gpu --version 0.34.1

# Verify GPU resources on all nodes
kubectl-homelab get node k8s-cp1 -o json | jq '.status.allocatable | with_entries(select(.key | startswith("gpu")))'
# Expect: "gpu.intel.com/i915": "3" on all 3 nodes
```

> **Note:** The operator runs privileged (needs `/var/lib/kubelet/device-plugins`). It automatically sets the `intel-device-plugins` namespace to PSS `privileged`. This is expected — device plugins inherently require host-level access.

---

## Step 4: Update Jellyfin Deployment

```bash
kubectl-homelab apply -f manifests/arr-stack/jellyfin/deployment.yaml

# Verify GPU allocated
kubectl-homelab -n arr-stack describe pod -l app=jellyfin | grep gpu.intel.com
# Expect: gpu.intel.com/i915: 1
```

**Changes from v0.23.0 Jellyfin deployment:**
- Added `gpu.intel.com/i915: "1"` to resources requests/limits
- Added `supplementalGroups: [44, 993]` (video, render groups)
- Added `emptyDir: {}` volume for `/config/transcodes` (disk-backed, not tmpfs)
- Increased memory limit from 2Gi to 4Gi (transcoding needs ~200-500Mi per stream)

---

## Step 5: Configure Jellyfin QSV in UI

Navigate to https://jellyfin.k8s.rommelporras.com → Administration Dashboard → Playback → Transcoding:

1. **Hardware acceleration:** Intel Quick Sync Video (QSV)
2. **QSV Device:** `/dev/dri/renderD128`
3. **Enable hardware decoding** for: H.264, HEVC, MPEG-2, VP9, HEVC 10bit, VP9 10bit
4. **Enable hardware encoding** + **Enable low-power encoding** for H.264 and HEVC
5. **Allow encoding in HEVC format:** Checked
6. **Enable tone mapping:** Checked
7. **Enable VPP tone mapping:** Checked (uses fixed-function hardware, not broken OpenCL path)
8. **Save** → acknowledge hardware acceleration warning

> **Tone Mapping Warning:** Jellyfin 10.11.x has a known bug ([#15576](https://github.com/jellyfin/jellyfin/issues/15576)) where OpenCL tone mapping produces blocky output on Intel GPUs. VPP tone mapping is unaffected and takes priority when both are enabled.

---

## Step 6: Apply Grafana Dashboards

```bash
kubectl-homelab apply -f manifests/monitoring/jellyfin-dashboard-configmap.yaml
kubectl-homelab apply -f manifests/monitoring/arr-stack-dashboard-configmap.yaml
```

**Jellyfin Media Server dashboard (11 panels):**
- Pod Status: Merged UP/DOWN + node placement (cp1/cp2/cp3), Uptime, Restarts, Transcode I/O
- GPU Allocation: Requested vs Allocatable per node, cluster-wide available/in-use
- Network Traffic: Jellyfin streaming throughput + Tailscale tunnel traffic
- Resource Usage: CPU + Memory with dashed request/limit lines

**ARR Media Stack dashboard (11 panels):**
- Pod Status: All 6 services with merged UP/DOWN + node placement
- Network Traffic: Receive + Transmit per service
- Resource Usage: CPU + Memory per service
- Container Restarts: All services (bottom)

---

## Verification

```bash
# All GPU pods running
kubectl-homelab -n intel-device-plugins get pods
kubectl-homelab -n node-feature-discovery get pods

# GPU resources on all nodes
for node in k8s-cp1 k8s-cp2 k8s-cp3; do
  echo "$node: $(kubectl-homelab get node $node -o json | jq -r '.status.allocatable["gpu.intel.com/i915"]')"
done
# Expect: 3 on each node

# Jellyfin has GPU
kubectl-homelab -n arr-stack describe pod -l app=jellyfin | grep gpu.intel.com

# Test QSV transcode (set bitrate limit low in Jellyfin app, check logs)
kubectl-homelab -n arr-stack logs -l app=jellyfin | grep -E "hevc_qsv|h264_qsv"
# Expect: hevc_qsv -low_power 1

# Find which node Jellyfin is on, then check GPU activity
NODE=$(kubectl-homelab -n arr-stack get pod -l app=jellyfin -o jsonpath='{.items[0].spec.nodeName}')
ssh wawashi@${NODE}.k8s.rommelporras.com sudo intel_gpu_top
# Video engine should show activity during transcode

# Dashboards loaded
# Visit: https://grafana.k8s.rommelporras.com → search "Jellyfin" and "ARR"
```

---

## Rollback

```bash
# Remove GPU from Jellyfin (revert deployment to CPU-only, remove GPU resources + supplementalGroups)
kubectl-homelab apply -f manifests/arr-stack/jellyfin/deployment.yaml  # (reverted version)

# Remove GPU plugin + operator
helm-homelab uninstall -n intel-device-plugins intel-device-plugins-gpu
helm-homelab uninstall -n intel-device-plugins intel-device-plugins-operator
kubectl-homelab delete namespace intel-device-plugins

# Remove NFD
helm-homelab uninstall -n node-feature-discovery node-feature-discovery
kubectl-homelab delete namespace node-feature-discovery

# Remove dashboards
kubectl-homelab -n monitoring delete configmap jellyfin-dashboard arr-stack-dashboard

# Node packages and i915.conf can stay — they don't affect anything without the K8s components
```
