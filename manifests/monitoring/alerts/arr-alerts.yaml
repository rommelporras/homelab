# PrometheusRule for ARR Stack + Network Alerts
# Phase 4.26: Monitor ARR app health, queue stalls, and network saturation
# Phase 4.28: Added ArrQueueWarning/ArrQueueError for stall-resolver automation feedback
#
# Metrics used:
#   scraparr_services_up — service health via Scraparr exporter
#   sonarr_queue_count/radarr_queue_count — active download queue via Scraparr
#   sonarr_queue_warning/radarr_queue_warning — queue items Sonarr/Radarr flagged as stalled
#   sonarr_queue_error/radarr_queue_error — queue items in hard error state
#   sonarr_missing_episodes_total/radarr_missing_movies_total — missing counts via Scraparr
#   node_network_*_bytes_total — NIC throughput from node-exporter
#   node_network_speed_bytes — NIC link speed from node-exporter
#   probe_success{job="jellyfin"} — HTTP probe from Blackbox Exporter
---
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: arr-alerts
  namespace: monitoring
  labels:
    release: prometheus
    app.kubernetes.io/part-of: kube-prometheus-stack
spec:
  groups:
    - name: arr-stack
      rules:
        # Scraparr exporter unreachable — all ARR metrics will be missing
        - alert: ArrAppDown
          expr: up{job="scraparr"} == 0
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: "Scraparr exporter is unreachable"
            description: "Scraparr metrics endpoint has been down for 5+ minutes. All ARR app monitoring is blind."
            runbook: |
              1. Check Scraparr pod status:
                 kubectl-homelab get pods -n arr-stack -l app=scraparr

              2. Check pod logs:
                 kubectl-homelab logs -n arr-stack deploy/scraparr --tail=50

              3. Verify ARR apps are running (Scraparr depends on their APIs):
                 kubectl-homelab get pods -n arr-stack

              4. If API key issues, re-run:
                 ./scripts/apply-arr-secrets.sh

        # Sonarr download queue stuck — items queued but nothing completing
        - alert: SonarrQueueStalled
          expr: sonarr_queue_count > 0 and changes(sonarr_missing_episodes_total[2h]) == 0
          for: 2h
          labels:
            severity: warning
          annotations:
            summary: "Sonarr download queue is stalled"
            description: "Sonarr has {{ $value }} items in download queue but missing episode count hasn't decreased in 2+ hours. Downloads may be stuck."
            runbook: |
              1. Check Sonarr Activity queue:
                 https://sonarr.k8s.rommelporras.com/activity/queue

              2. Check qBittorrent for stalled downloads:
                 https://qbittorrent.k8s.rommelporras.com

              3. Check Prowlarr for indexer health:
                 https://prowlarr.k8s.rommelporras.com/system/status

        # Radarr download queue stuck — items queued but nothing completing
        - alert: RadarrQueueStalled
          expr: radarr_queue_count > 0 and changes(radarr_missing_movies_total[2h]) == 0
          for: 2h
          labels:
            severity: warning
          annotations:
            summary: "Radarr download queue is stalled"
            description: "Radarr has {{ $value }} items in download queue but missing movie count hasn't decreased in 2+ hours. Downloads may be stuck."
            runbook: |
              1. Check Radarr Activity queue:
                 https://radarr.k8s.rommelporras.com/activity/queue

              2. Check qBittorrent for stalled downloads:
                 https://qbittorrent.k8s.rommelporras.com

              3. Check Prowlarr for indexer health:
                 https://prowlarr.k8s.rommelporras.com/system/status

    - name: network
      rules:
        # NIC utilization sustained above 80% — 2.5GbE upgrade may be justified
        - alert: NetworkInterfaceSaturated
          expr: |
            (
              rate(node_network_receive_bytes_total{device!~"lo|cni.*|veth.*|cilium.*|lxc.*"}[5m])
              + rate(node_network_transmit_bytes_total{device!~"lo|cni.*|veth.*|cilium.*|lxc.*"}[5m])
            )
            / clamp_min(node_network_speed_bytes{device!~"lo|cni.*|veth.*|cilium.*|lxc.*"}, 125000000)
            * 100 > 80
          for: 10m
          labels:
            severity: warning
          annotations:
            summary: "NIC utilization above 80% on {{ $labels.instance }}"
            description: "{{ $labels.device }} on {{ $labels.instance }} is at {{ $value | humanize }}% utilization for 10+ minutes. Consider 2.5GbE NIC upgrade."
            runbook: |
              1. Check Network Throughput dashboard in Grafana

              2. Identify which pods are generating traffic:
                 kubectl-homelab top pod -A --sort-by=cpu

              3. If NFS-related, check qBittorrent download activity

              4. If sustained during off-hours, this is likely Tdarr transcoding

        # NIC utilization critical — active bottleneck
        - alert: NetworkInterfaceCritical
          expr: |
            (
              rate(node_network_receive_bytes_total{device!~"lo|cni.*|veth.*|cilium.*|lxc.*"}[5m])
              + rate(node_network_transmit_bytes_total{device!~"lo|cni.*|veth.*|cilium.*|lxc.*"}[5m])
            )
            / clamp_min(node_network_speed_bytes{device!~"lo|cni.*|veth.*|cilium.*|lxc.*"}, 125000000)
            * 100 > 95
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: "NIC critically saturated on {{ $labels.instance }}"
            description: "{{ $labels.device }} on {{ $labels.instance }} is at {{ $value | humanize }}% utilization for 5+ minutes. Network is a bottleneck — downloads, streaming, and NFS will be degraded."
            runbook: |
              1. Check if Tdarr is running a large batch transcode:
                 https://tdarr.k8s.rommelporras.com

              2. If yes, pause Tdarr queue to restore bandwidth

              3. Check qBittorrent for many simultaneous downloads:
                 https://qbittorrent.k8s.rommelporras.com

              4. Consider 2.5GbE NIC upgrade if this is frequent

    - name: arr-companions
      rules:
        # Seerr (Overseerr) request portal unreachable
        - alert: SeerrDown
          expr: probe_success{job="seerr"} == 0
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "Seerr request portal is unreachable"
            description: "Blackbox HTTP probe to seerr.arr-stack.svc:5055 has failed for 5+ minutes. Users cannot submit media requests."
            runbook: |
              1. Check pod status:
                 kubectl-homelab get pods -n arr-stack -l app=seerr

              2. Check pod logs:
                 kubectl-homelab logs -n arr-stack deploy/seerr --tail=50

              3. Verify Sonarr/Radarr connectivity (Seerr depends on them):
                 kubectl-homelab get pods -n arr-stack -l app=sonarr
                 kubectl-homelab get pods -n arr-stack -l app=radarr

              4. Check events:
                 kubectl-homelab describe pod -n arr-stack -l app=seerr

        # Tdarr GPU transcoding service unreachable
        - alert: TdarrDown
          expr: probe_success{job="tdarr"} == 0
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "Tdarr transcoding service is unreachable"
            description: "Blackbox HTTP probe to tdarr.arr-stack.svc:8265 has failed for 5+ minutes. GPU transcoding is unavailable."
            runbook: |
              1. Check pod status:
                 kubectl-homelab get pods -n arr-stack -l app=tdarr

              2. Check pod logs:
                 kubectl-homelab logs -n arr-stack deploy/tdarr --tail=50

              3. Check GPU device plugin:
                 kubectl-homelab get pods -n kube-system -l app=intel-gpu-plugin

              4. Check events:
                 kubectl-homelab describe pod -n arr-stack -l app=tdarr

        # Byparr Cloudflare bypass proxy unreachable
        - alert: ByparrDown
          expr: probe_success{job="byparr"} == 0
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "Byparr Cloudflare bypass proxy is unreachable"
            description: "Blackbox HTTP probe to byparr.arr-stack.svc:8191 has failed for 5+ minutes. Prowlarr cannot reach Cloudflare-protected indexers."
            runbook: |
              1. Check pod status:
                 kubectl-homelab get pods -n arr-stack -l app=byparr

              2. Check pod logs:
                 kubectl-homelab logs -n arr-stack deploy/byparr --tail=50

              3. Check events:
                 kubectl-homelab describe pod -n arr-stack -l app=byparr

    - name: arr-queue-health
      rules:
        # Sonarr/Radarr have flagged queue items as stalled (no seeds, no connections)
        # The arr-stall-resolver CronJob handles these every 30 min automatically:
        #   → switches quality profile to "Any" + blocklists release + triggers re-search
        # This alert fires after 60m (2 CronJob cycles) — means automation couldn't fix it.
        # Common causes: content not on any indexer, all indexers down, Prowlarr config issue.
        - alert: ArrQueueWarning
          expr: (sum(sonarr_queue_warning) + sum(radarr_queue_warning)) > 0
          for: 60m
          labels:
            severity: warning
          annotations:
            summary: "ARR stalled downloads not resolved after 60 minutes"
            description: "{{ $value }} queue item(s) have been stalled for 60+ minutes. The stall-resolver ran twice but couldn't clear them. The release may not exist on any indexer at any quality."
            runbook: |
              1. Check stall-resolver CronJob logs (last 3 runs):
                 kubectl-homelab logs -n arr-stack -l app=arr-stall-resolver --tail=100

              2. Check Sonarr/Radarr Activity queues for specific items:
                 https://sonarr.k8s.rommelporras.com/activity/queue
                 https://radarr.k8s.rommelporras.com/activity/queue

              3. Check Prowlarr indexer health (no results = content not available):
                 https://prowlarr.k8s.rommelporras.com/indexers

              4. If indexers are healthy but no releases found, the content may not
                 be available yet — remove from queue and re-add when released.

        # Sonarr/Radarr queue items in hard error state for 15+ minutes.
        # Two distinct causes — check the CronJob logs to determine which:
        #   state=stopped    → download failed (no seeds). stall-resolver handled it automatically.
        #   state=importFailed/importBlocked → torrent downloaded but import failed.
        #                      stall-resolver skips these. Manual fix required (NFS/disk/perms).
        - alert: ArrQueueError
          expr: (sum(sonarr_queue_error) + sum(radarr_queue_error)) > 0
          for: 15m
          labels:
            severity: critical
          annotations:
            summary: "ARR queue has items in hard error state"
            description: "{{ $value }} queue item(s) are in error state for 15+ minutes. Check CronJob logs to determine if this is a stalled download (handled automatically) or an import failure (needs manual fix)."
            runbook: |
              1. Check stall-resolver logs to determine the error type:
                 kubectl-homelab logs -n arr-stack -l app=arr-stall-resolver --tail=100

                 If logs show [SKIP/IMPORT]: torrent downloaded OK, import failed.
                   → Go to step 3 (NFS/disk/perms issue).
                 If logs show [ERROR] with state=stopped: download failed, automation acted.
                   → Check Prowlarr for indexer health (step 4).

              2. Check Sonarr/Radarr queue for error details:
                 https://sonarr.k8s.rommelporras.com/activity/queue
                 https://radarr.k8s.rommelporras.com/activity/queue

              3. For import failures — check NFS and disk:
                 kubectl-homelab exec -n arr-stack deploy/sonarr -- df -h /data
                 kubectl-homelab get pvc -n arr-stack
                 https://omv.home.rommelporras.com  (NAS disk usage)

              4. For download failures — check indexer availability:
                 https://prowlarr.k8s.rommelporras.com/indexers

              5. Check qBittorrent for stuck torrents:
                 https://qbit.k8s.rommelporras.com

    - name: jellyfin
      rules:
        # Jellyfin media server unreachable
        - alert: JellyfinDown
          expr: probe_success{job="jellyfin"} == 0
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: "Jellyfin media server is unreachable"
            description: "Jellyfin health probe has failed for 5+ minutes. Media streaming is unavailable."
            runbook: |
              1. Check Jellyfin pod status:
                 kubectl-homelab get pods -n arr-stack -l app=jellyfin

              2. Check pod logs:
                 kubectl-homelab logs -n arr-stack deploy/jellyfin --tail=50

              3. Check if NFS mount is healthy:
                 kubectl-homelab exec -n arr-stack deploy/jellyfin -- ls /data/media/

              4. Check GPU device plugin (QSV):
                 kubectl-homelab get pods -n kube-system -l app=intel-gpu-plugin
